# Mission → Code Bridge — Evaluation

This report is generated by `scripts/graph_core_eval.py` in the engine repo.

## Metrics

```json
{
  "expected_bridges": 3,
  "actual_bridges": 3,
  "precision": 1.0,
  "recall": 1.0
}
```

See `eval.json` for full details (samples, counts, and metadata).

